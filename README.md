# Vision Transformer vs CNN - Klasyfikacja medyczna

Projekt badawczy porÃ³wnujÄ…cy efektywnoÅ›Ä‡ Vision Transformers i Convolutional Neural Networks w klasyfikacji dermatologicznej.

## ğŸ“‹ Hipoteza badawcza

**"Vision Transformers osiÄ…gajÄ… lepszÄ… dokÅ‚adnoÅ›Ä‡ niÅ¼ tradycyjne CNN w klasyfikacji zdjÄ™Ä‡ dermatologicznych, szczegÃ³lnie przy ograniczonych danych treningowych"**

## ğŸš€ Szybki start

```bash
# 1. Zbuduj obraz Docker
docker-compose build

# 2. przygotowanie datasetu
docker-compose run --rm prepare-data

# 3. Pierwszy eksperyment
docker-compose run --rm comparison
```

## ğŸ“ Struktura projektu

```
project/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ dataset.py          # HAM10000 dataset loader
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ vision_transformer.py    # ViT implementation
â”‚   â”‚   â”œâ”€â”€ cnn_models.py            # CNN implementations
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ trainer.py          # Training loop
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â””â”€â”€ evaluation/
â”‚       â””â”€â”€ __init__.py
â”œâ”€â”€ data/                       # Dane (tworzone automatycznie)
â”œâ”€â”€ results/                    # Wyniki eksperymentÃ³w
â”œâ”€â”€ checkpoints/                # Zapisane modele
â”œâ”€â”€ logs/                       # Logi treningÃ³w
â”œâ”€â”€ config.py                   # Konfiguracja projektu
â”œâ”€â”€ main.py                     # GÅ‚Ã³wny skrypt
â”œâ”€â”€ test_setup.py               # Test konfiguracji
â”œâ”€â”€ requirements.txt            # ZaleÅ¼noÅ›ci
â””â”€â”€ README.md                   # Ten plik
```

## ğŸ”§ Konfiguracja
```bash
# .env
KAGGLE_USERNAME=twoj_username
KAGGLE_KEY=twÃ³j_klucz_api_z_kaggle.json
WANDB_API_KEY=twoj_klucz_api_wandb
```

### GÅ‚Ã³wne ustawienia w `config.py`:

- **Dataset**: HAM10000 (7 klas dermatologicznych) - pobierany automatycznie z Kaggle
- **Modele**: ViT-Base, ResNet50, EfficientNet-B0
- **Batch size**: 32
- **Learning rate**: 1e-4
- **Epochs**: 100 (z early stopping)

## ğŸ“Š DostÄ™pne modele

### Vision Transformers
- `google/vit-base-patch16-224` - ViT Base
- `google/vit-large-patch16-224` - ViT Large

### CNN
- `resnet18`, `resnet50`, `resnet101` - ResNet family
- `efficientnet_b0`, `efficientnet_b1` - EfficientNet family
- `densenet121` - DenseNet

## ğŸ¯ Eksperymenty do hipotezy
Projekt automatycznie testuje:

1. **WpÅ‚yw rozmiaru datasetu** (10%, 25%, 50%, 100% danych)
2. **PorÃ³wnanie architektur** (ViT vs rÃ³Å¼ne CNN)

## ğŸ“ˆ Wyniki

Wyniki sÄ… zapisywane w folderze `results/` w formacie:

```
results/
â”œâ”€â”€ vit_google_vit-base-patch16-224_20241215_143022/
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ results.json
â”‚   â””â”€â”€ best_model.pth
â””â”€â”€ comparison_summary_20241215_150000.json
```

### Interpretacja wynikÃ³w

- `accuracy` - DokÅ‚adnoÅ›Ä‡ klasyfikacji
- `f1_weighted` - F1-score waÅ¼ony
- `classification_report` - SzczegÃ³Å‚owy raport dla kaÅ¼dej klasy
- `confusion_matrix` - Macierz pomyÅ‚ek

## ğŸ³ Docker - SzczegÃ³Å‚y

### DostÄ™pne serwisy

```bash
# Przygotowanie danych
docker-compose run --rm prepare-data

# PeÅ‚ne porÃ³wnanie
docker-compose run --rm comparison

### GPU Support w Docker

Aby uÅ¼ywaÄ‡ GPU, odkomentuj sekcjÄ™ w `docker-compose.yml`:

```yaml
deploy:
  resources:
    reservations:
      devices:
        - driver: nvidia
          count: 1
          capabilities: [gpu]
```

### Volumes

Docker automatycznie mountuje:
- `./data` â†’ `/app/data` (dane)
- `./results` â†’ `/app/results` (wyniki)
- `./logs` â†’ `/app/logs` (logi)
- `./checkpoints` â†’ `/app/checkpoints` (modele)

## ğŸ“š Dataset

Projekt uÅ¼ywa HAM10000 - dataset do klasyfikacji zmian skÃ³rnych:

- **Klasy**: 7 (akiec, bcc, bkl, df, mel, nv, vasc)
- **Obrazy**: ~10,000 zdjÄ™Ä‡ dermatologicznych
- **Format**: JPEG, normalizowane do 224x224

## ğŸ“ Cele badawcze

1. **PorÃ³wnanie dokÅ‚adnoÅ›ci** ViT vs CNN
2. **Analiza wpÅ‚ywu rozmiaru datasetu** na performance
3. **InterpretabilnoÅ›Ä‡** - attention maps vs feature maps
4. **EfektywnoÅ›Ä‡ obliczeniowa** - czas treningu, liczba parametrÃ³w